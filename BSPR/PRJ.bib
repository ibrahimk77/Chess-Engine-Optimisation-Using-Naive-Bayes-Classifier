@online{androutsopoulosEvaluationNaiveBayesian2000,
  title = {An Evaluation of {{Naive Bayesian}} Anti-Spam Filtering},
  author = {Androutsopoulos, Ion and Koutsias, John and Chandrinos, Konstantinos V. and Paliouras, George and Spyropoulos, Constantine D.},
  date = {2000-06-07},
  eprint = {cs/0006013},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.cs/0006013},
  url = {http://arxiv.org/abs/cs/0006013},
  urldate = {2025-03-21},
  abstract = {It has recently been argued that a Naive Bayesian classifier can be used to filter unsolicited bulk e-mail ("spam"). We conduct a thorough evaluation of this proposal on a corpus that we make publicly available, contributing towards standard benchmarks. At the same time we investigate the effect of attribute-set size, training-corpus size, lemmatization, and stop-lists on the filter's performance, issues that had not been previously explored. After introducing appropriate cost-sensitive evaluation measures, we reach the conclusion that additional safety nets are needed for the Naive Bayesian anti-spam filter to be viable in practice.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\LN9PXXDD\\Androutsopoulos et al. - 2000 - An evaluation of Naive Bayesian anti-spam filtering.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\67GB8FHA\\0006013.html}
}

@book{averbakhHistoryChessChaturanga2012,
  title = {A {{History}} of {{Chess}}: {{From Chaturanga}} to the {{Present Day}}},
  shorttitle = {A {{History}} of {{Chess}}},
  author = {Averbakh, Yuri},
  date = {2012-12-05},
  eprint = {uJBXDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {SCB Distributors},
  abstract = {Chess: An Historical Perspective  Chess � the �Royal Game” � is an ancient board game, perhaps fifteen hundred years old. There are many legends about how chess came to be. Most of them are folk tales and are far from reality.  Arguably more books have been written about chess than all the other games combined, but relatively little has been written about the history of chess. The topic is difficult; it requires thorough knowledge, and there are still many unknown historical pitfalls. It is therefore no surprise that there exist a variety of hypotheses concerning the origin of chess.  In this book, the author, legendary Russian grandmaster Yuri Averbakh, presents a well-researched and documented theory about the origins, development and spread of this immensely popular game. In addition, over three dozen splendid color plates � presented on coated stock making the images suitable for framing � supplement his historical analysis.},
  isbn = {978-1-936490-45-5},
  langid = {english},
  pagetotal = {145},
  keywords = {Games & Activities / Chess}
}

@inproceedings{davidDeepChessEndtoEndDeep2016,
  title = {{{DeepChess}}: {{End-to-End Deep Neural Network}} for {{Automatic Learning}} in {{Chess}}},
  shorttitle = {{{DeepChess}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} – {{ICANN}} 2016},
  author = {David, Omid E. and Netanyahu, Nathan S. and Wolf, Lior},
  editor = {Villa, Alessandro E.P. and Masulli, Paolo and Pons Rivero, Antonio Javier},
  date = {2016},
  pages = {88--96},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-44781-0_11},
  abstract = {We present an end-to-end learning method for chess, relying on deep neural networks. Without any a priori knowledge, in particular without any knowledge regarding the rules of chess, a deep neural network is trained using a combination of unsupervised pretraining and supervised training. The unsupervised training extracts high level features from a given position, and the supervised training learns to compare two chess positions and select the more favorable one. The training relies entirely on datasets of several million chess games, and no further domain specific knowledge is incorporated.},
  isbn = {978-3-319-44781-0},
  langid = {english},
  keywords = {Chess Game,Deep Belief Network,Deep Neural Network,High Level Feature,Supervise Training},
  file = {C:\Users\ibyad\Zotero\storage\W48S2T4Q\David et al. - 2016 - DeepChess End-to-End Deep Neural Network for Automatic Learning in Chess.pdf}
}

@book{davidsonShortHistoryChess2012,
  title = {A {{Short History}} of {{Chess}}},
  author = {Davidson, Henry A.},
  date = {2012-10-10},
  eprint = {PQBpr6KAdHkC},
  eprinttype = {googlebooks},
  publisher = {Crown},
  abstract = {A compact and comprehensive chronicle of the~worldwide origins and history of the game of~chess—from 500 A.D. to its modern gameplay today~Have you ever wondered what the pieces in the~chessboard mean or why each piece has a unique move? In~A Short History of~Chess, Henry~A.~Davidson explores the ancient roots of~chess~and the developments around the world that led to the modern version of the popular game. For people new to the game and experienced players alike, Davidson includes a polyglot—a lexicon of~chess~terms in the forty major languages of the world. And for the skeptical reader or those interested in learning more, there is also a working bibliography of English language references.},
  isbn = {978-0-307-82829-3},
  langid = {english},
  pagetotal = {219},
  keywords = {Games & Activities / Chess,Games & Activities / Reference,History / Social History}
}

@article{decredicoUsingMachineLearning,
  title = {Using {{Machine Learning Algorithms}} to {{Predict Outcomes}} of {{Chess Games Using Player Data}}},
  author = {DeCredico, Sofia},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\S35L9VPZ\DeCredico - Using Machine Learning Algorithms to Predict Outcomes of Chess Games Using Player Data.pdf}
}

@article{departmentofcomputerscienceandengineeringjaypeeinstituteofinformationtechnologynoida201304indiaStatisticalAnalysisResult2018,
  title = {Statistical {{Analysis}} on {{Result Prediction}} in {{Chess}}},
  author = {{Department of Computer Science and Engineering, Jaypee Institute of Information Technology, Noida, 201304, India} and Lehana, Paras and Kulshrestha, Sudhanshu and Thakur, Nitin and Asthana, Pradeep},
  date = {2018-07-08},
  journaltitle = {International Journal of Information Engineering and Electronic Business},
  shortjournal = {IJIEEB},
  volume = {10},
  number = {4},
  pages = {25--32},
  issn = {20749023, 20749031},
  doi = {10.5815/ijieeb.2018.04.04},
  url = {http://www.mecs-press.org/ijieeb/ijieeb-v10-n4/v10n4-4.html},
  urldate = {2024-12-12},
  abstract = {In this paper, authors have proposed a technique which uses the existing database of chess games and machine learning algorithms to predict the game results. Authors have also developed various relationships among different combinations of attributes like half-moves, move sequence, chess engine evaluated score, opening sequence and the game result. The database of 10,000 actual chess games, imported and processed using Shane’s Chess Information Database (SCID), is annotated with evaluation score for each halfmove using Stockfish chess engine running constantly on depth 17. This provided us with a total of 8,40,289 board evaluations. The idea is to make the Multi-Variate Linear Regression algorithm learn from these evaluation scores for same sequence of opening moves and game outcome, then using it to calculate the winning score of a side for each possible move and thus suggesting the move with highest score. The output is also tested with including move details. Game attributes are also classified into classes. Using Naïve Bayes classification, the data result is classified into three classes namely move preferable to white, black or a tie and then the data is validated on 20\% of the dataset to determine accuracies for different combinations of considered attributes.},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\ZLFBK2FJ\Department of Computer Science and Engineering, Jaypee Institute of Information Technology, Noida, 201304, India et al. - 2018 - Statistical Analysis on Result Prediction in Chess.pdf}
}

@article{eberhardtBayesianSpamDetection2015,
  title = {Bayesian {{Spam Detection}}},
  author = {Eberhardt, Jeremy J.},
  date = {2015-03-16},
  journaltitle = {Scholarly Horizons: University of Minnesota, Morris Undergraduate Journal},
  shortjournal = {Scholarly Horizons: University of Minnesota, Morris Undergraduate Journal},
  volume = {2},
  number = {1},
  issn = {2576-2176},
  doi = {10.61366/2576-2176.1024},
  url = {https://digitalcommons.morris.umn.edu/horizons/vol2/iss1/2},
  urldate = {2024-12-13},
  abstract = {Spammers always find new ways to get spammy content to the public. Very commonly this is accomplished by using email, social media, or advertisements. According to a 2011 report by the Messaging Anti-Abuse Working Group roughly 90\% of all emails in the United States are spam. This is why we will be taking a more detailed look at email spam. Spam filters have been getting better at detecting spam and removing it, but no method is able to block 100\% of it. Because of this, many different methods of text classification have been developed, including a group of classifiers that use a Bayesian approach. The Bayesian approach to spam filtering was one of the earliest methods used to filter spam, and it remains relevant to this day.},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\W9KJYCWS\Eberhardt - 2015 - Bayesian Spam Detection.pdf}
}

@article{fernandezBayesChessComputerChess2008,
  title = {{{BayesChess}}: {{A}} Computer Chess Program Based on {{Bayesian}} Networks},
  shorttitle = {{{BayesChess}}},
  author = {Fernández, Antonio and Salmerón, Antonio},
  date = {2008-06-01},
  journaltitle = {Pattern Recognition Letters},
  shortjournal = {Pattern Recognition Letters},
  series = {Pattern {{Recognition}} in {{Interdisciplinary Perception}} and {{Intelligence}}},
  volume = {29},
  number = {8},
  pages = {1154--1159},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2007.06.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865507002127},
  urldate = {2024-12-12},
  abstract = {In this paper, we introduce a chess program able to adapt its game strategy to its opponent, as well as to adapt the evaluation function that guides the search process according to its playing experience. The adaptive and learning abilities have been implemented through Bayesian networks. We show how the program learns through an experiment consisting on a series of games that point out that the results improve after the learning stage.},
  keywords = {Adaptive learning,Bayesian networks,Computer chess},
  file = {C:\Users\ibyad\Zotero\storage\UV7GCPE4\Fernández and Salmerón - 2008 - BayesChess A computer chess program based on Bayesian networks.pdf}
}

@article{ghodasaraOverviewDecisionTree2021,
  title = {Overview of {{Decision Tree Pruning}} in {{Machine Learning}}},
  author = {Ghodasara, Kavisha},
  date = {2021},
  volume = {08},
  number = {08},
  abstract = {This document serves as an introduction to the Pruning of Decision Trees. Pruning, which serves to find a sparse subnetwork in a dense network that has the same overall accuracy, helps in reducing the space requirements and cost in operating the network. An introduction to the different approaches to pruning, types of pruning has been mentioned. The Lottery Ticket Hypothesis [1] has been mentioned in order to support the advantages of pruning, along with the strategies employed to do so. Alpha-beta Pruning, which often finds its use in multiplayer gaming to determine the next best moves to be made by a machine, has also been discussed. The merits and demerits of pruning so mentioned help in determining whether pruning would be a feasible option or not.},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\VQ4FMAGC\Ghodasara - 2021 - Overview of Decision Tree Pruning in Machine Learning.pdf}
}

@article{guptaDeterminingChessPiece2023,
  title = {Determining {{Chess Piece Values Using Machine Learning}}},
  author = {Gupta, Aditya and Grattoni, Christopher and Gupta, Arnav},
  date = {2023-02-28},
  journaltitle = {Journal of Student Research},
  shortjournal = {J Stud Res},
  volume = {12},
  number = {1},
  issn = {2167-1907},
  doi = {10.47611/jsrhs.v12i1.4356},
  url = {https://www.jsr.org/hs/index.php/path/article/view/4356},
  langid = {american},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\WCSQJ9PR\\Gupta et al. - 2023 - Determining Chess Piece Values Using Machine Learning.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\9JUN5IR8\\1910.html}
}

@article{hsuIBMsDeepBlue1999,
  title = {{{IBM}}'s {{Deep Blue Chess}} Grandmaster Chips},
  author = {Hsu, Feng-Hsiung},
  date = {1999-03},
  journaltitle = {IEEE Micro},
  volume = {19},
  number = {2},
  pages = {70--81},
  issn = {1937-4143},
  doi = {10.1109/40.755469},
  url = {https://ieeexplore.ieee.org/abstract/document/755469},
  urldate = {2024-12-12},
  abstract = {The IBM Deep Blue supercomputer that defeated World Chess Champion Garry Kasparov in 1997 employed 480 custom chess chips. This article describes the design philosophy, general architecture, and performance of the chess chips, which provided most of Deep Blue's computational power.},
  eventtitle = {{{IEEE Micro}}},
  keywords = {Computer architecture,Computer science,Emulation,Games,Hardware,Humans,Programming profession,Supercomputers},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\26SJMB6T\\Hsu - 1999 - IBM's Deep Blue Chess grandmaster chips.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\5R2FFFJI\\755469.html}
}

@article{igeAIPoweredAntiCyber2022,
  title = {{{AI Powered Anti-Cyber Bullying System}} Using {{Machine Learning Algorithm}} of {{Multinomial Naïve Bayes}} and {{Optimized Linear Support Vector Machine}}},
  author = {Ige, Tosin and Adewale, Sikiru},
  date = {2022},
  journaltitle = {International Journal of Advanced Computer Science and Applications},
  shortjournal = {IJACSA},
  volume = {13},
  number = {5},
  issn = {21565570, 2158107X},
  doi = {10.14569/IJACSA.2022.0130502},
  url = {http://thesai.org/Publications/ViewPaper?Volume=13&Issue=5&Code=IJACSA&SerialNo=2},
  urldate = {2025-03-13},
  abstract = {Unless and until our society recognizes cyber bullying for what it is, the suffering of thousands of silent victims will continue.” \textasciitilde{} Anna Maria Chavez. There had been series of research on cyber bullying which are unable to provide reliable solution to cyber bullying. In this research work, we were able to provide a permanent solution to this by developing a model capable of detecting and intercepting bullying incoming and outgoing messages with 92\% accuracy. We also developed a chatbot automation messaging system to test our model leading to the development of Artificial Intelligence powered anti-cyber bullying system using machine learning algorithm of Multinomial Naïve Bayes (MNB) and optimized linear Support Vector Machine (SVM). Our model is able to detect and intercept bullying outgoing and incoming bullying messages and take immediate action.},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\B64L2TPG\Ige and Adewale - 2022 - AI Powered Anti-Cyber Bullying System using Machine Learning Algorithm of Multinomial Naïve Bayes an.pdf}
}

@inproceedings{kamelCancerClassificationUsing2019,
  title = {Cancer {{Classification Using Gaussian Naive Bayes Algorithm}}},
  booktitle = {2019 {{International Engineering Conference}} ({{IEC}})},
  author = {Kamel, Hajer and Abdulah, Dhahir and Al-Tuwaijari, Jamal M.},
  date = {2019-06},
  pages = {165--170},
  doi = {10.1109/IEC47844.2019.8950650},
  url = {https://ieeexplore.ieee.org/abstract/document/8950650},
  urldate = {2024-12-12},
  abstract = {Cancer is one of the most deadly diseases in the world and it is a subject of concern because until till date they cannot found the real treatment for this disease. If and only if this disease is detected in early stage, patients having this disease can be saved. If it is detected in latter stage then chance of survival will be very less. Because of this, early and true diagnosis is an important issue and plays a key role to cure this disease. In the work, Gaussian Naive Bayes algorithm is used for classification cancer. The algorithm is tested by applying it on two datasets in which the first is Wisconsin Breast Cancer dataset (WBCD) and the second is lung cancer dataset. The evaluation results of the proposed algorithm have achieved 98\% accuracy of predicting breast cancer and 90\% of predicting lung cancer.},
  eventtitle = {2019 {{International Engineering Conference}} ({{IEC}})},
  keywords = {Cancer,Classification,Pre-processesing and Gaussian Naï ve Bayes,Z- Score Normalization},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\6XKELY7B\\Kamel et al. - 2019 - Cancer Classification Using Gaussian Naive Bayes Algorithm.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\C4QZLJDI\\8950650.html}
}

@online{KingSafetyChessprogramming,
  title = {King {{Safety}} - {{Chessprogramming}} Wiki},
  url = {https://www.chessprogramming.org/King_Safety},
  urldate = {2024-12-11},
  file = {C:\Users\ibyad\Zotero\storage\V6VX47SV\King_Safety.html}
}

@online{kleinNeuralNetworksChess2022,
  title = {Neural {{Networks}} for {{Chess}}},
  author = {Klein, Dominik},
  date = {2022-09-03},
  eprint = {2209.01506},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.01506},
  url = {http://arxiv.org/abs/2209.01506},
  urldate = {2024-12-12},
  abstract = {AlphaZero, Leela Chess Zero and Stockfish NNUE revolutionized Computer Chess. This book gives a complete introduction into the technical inner workings of such engines. The book is split into four main chapters -- excluding chapter 1 (introduction) and chapter 6 (conclusion): Chapter 2 introduces neural networks and covers all the basic building blocks that are used to build deep networks such as those used by AlphaZero. Contents include the perceptron, back-propagation and gradient descent, classification, regression, multilayer perceptron, vectorization techniques, convolutional networks, squeeze and excitation networks, fully connected networks, batch normalization and rectified linear units, residual layers, overfitting and underfitting. Chapter 3 introduces classical search techniques used for chess engines as well as those used by AlphaZero. Contents include minimax, alpha-beta search, and Monte Carlo tree search. Chapter 4 shows how modern chess engines are designed. Aside from the ground-breaking AlphaGo, AlphaGo Zero and AlphaZero we cover Leela Chess Zero, Fat Fritz, Fat Fritz 2 and Efficiently Updatable Neural Networks (NNUE) as well as Maia. Chapter 5 is about implementing a miniaturized AlphaZero. Hexapawn, a minimalistic version of chess, is used as an example for that. Hexapawn is solved by minimax search and training positions for supervised learning are generated. Then as a comparison, an AlphaZero-like training loop is implemented where training is done via self-play combined with reinforcement learning. Finally, AlphaZero-like training and supervised training are compared.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\XAP6HNDF\\Klein - 2022 - Neural Networks for Chess.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\ZVTVESEL\\2209.html}
}

@article{knuthAnalysisAlphabetaPruning1975,
  title = {An Analysis of Alpha-Beta Pruning},
  author = {Knuth, Donald E. and Moore, Ronald W.},
  date = {1975-12-01},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {6},
  number = {4},
  pages = {293--326},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(75)90019-3},
  url = {https://www.sciencedirect.com/science/article/pii/0004370275900193},
  urldate = {2025-03-13},
  abstract = {The alpha-beta technique for searching game trees is analyzed, in an attempt to provide some insight into its behavior. The first portion of this paper is an expository presentation of the method together with a proof of its correctness and a historical discussion. The alpha-beta procedure is shown to be optimal in a certain sense, and bounds are obtained for its running time with various kinds of random data.},
  file = {C:\Users\ibyad\Zotero\storage\KIYQBS3F\0004370275900193.html}
}

@inproceedings{lowdNaiveBayesModels2005,
  title = {Naive {{Bayes}} Models for Probability Estimation},
  author = {Lowd, Daniel and Domingos, Pedro},
  date = {2005-01},
  doi = {10.1145/1102351.1102418},
  url = {https://www.researchgate.net/publication/221346504_Naive_Bayes_models_for_probability_estimation},
  urldate = {2024-12-11},
  abstract = {PDF | Naive Bayes models have been widely used for clustering and classification. However, they are seldom used for general probabilistic learning and... | Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\Z9RG42FZ\221346504_Naive_Bayes_models_for_probability_estimation.html}
}

@book{mikhalchishinCentreModernStrategy,
  title = {The {{Centre}}. {{A}} Modern Strategy Guide},
  author = {Mikhalchishin, Adrian and Mohr, Georg},
  url = {https://www.alphaechecs.fr/assets/pdf/products/the-center-a-modern-strategy-guide.pdf},
  isbn = {978-83-945362-9-9}
}

@article{murphyNaiveBayesClassifiers2006,
  title = {Naive {{Bayes}} Classifiers},
  author = {Murphy, Kevin P},
  date = {2006-10-24},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\GMRUY3AH\Murphy - Last updated October 24, 2006.pdf}
}

@book{newbornKasparovDeepBlue1997,
  title = {Kasparov versus {{Deep Blue}}},
  author = {Newborn, Monty},
  date = {1997},
  publisher = {Springer},
  location = {New York, NY},
  doi = {10.1007/978-1-4612-2260-6},
  url = {http://link.springer.com/10.1007/978-1-4612-2260-6},
  urldate = {2024-12-10},
  isbn = {978-1-4612-7477-3 978-1-4612-2260-6},
  langid = {english},
  keywords = {chess,computer chess,computer chess championship,Deep Blue,Kasparov}
}

@online{NLPinChess,
  title = {{{SentiMATE}}: {{Learning}} to Play {{Chess}} through {{Natural Language Processing}}},
  shorttitle = {{{SentiMATE}}},
  author = {Kamlish, Isaac and Chocron, Isaac Bentata and McCarthy, Nicholas},
  date = {2019-09-25},
  eprint = {1907.08321},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1907.08321},
  url = {http://arxiv.org/abs/1907.08321},
  urldate = {2024-12-10},
  abstract = {We present SentiMATE, a novel end-to-end Deep Learning model for Chess, employing Natural Language Processing that aims to learn an effective evaluation function assessing move quality. This function is pre-trained on the sentiment of commentary associated with the training moves and is used to guide and optimize the agent's game-playing decision making. The contributions of this research are three-fold: we build and put forward both a classifier which extracts commentary describing the quality of Chess moves in vast commentary datasets, and a Sentiment Analysis model trained on Chess commentary to accurately predict the quality of said moves, to then use those predictions to evaluate the optimal next move of a Chess agent. Both classifiers achieve over 90 \% classification accuracy. Lastly, we present a Chess engine, SentiMATE, which evaluates Chess moves based on a pre-trained sentiment evaluation function. Our results exhibit strong evidence to support our initial hypothesis - "Can Natural Language Processing be used to train a novel and sample efficient evaluation function in Chess Engines?" - as we integrate our evaluation function into modern Chess engines and play against agents with traditional Chess move evaluation functions, beating both random agents and a DeepChess implementation at a level-one search depth - representing the number of moves a traditional Chess agent (employing the alpha-beta search algorithm) looks ahead in order to evaluate a given chess state.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\MITFITBV\\Kamlish et al. - 2019 - SentiMATE Learning to play Chess through Natural Language Processing.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\HTDHSB4P\\1907.html}
}

@online{PassedPawnChesscom,
  title = {Passed  {{Pawn}} - {{Chess}}.Com},
  url = {https://www.chess.com/terms/passed-pawn},
  urldate = {2024-12-11},
  abstract = {Learn what a passed pawn is in chess! All of the information you need to know about passed pawns, types of passed pawns, and their importance in the royal game!},
  langid = {american},
  organization = {Chess.com},
  file = {C:\Users\ibyad\Zotero\storage\JY9UUZTV\passed-pawn.html}
}

@online{PawnStructureChessprogramming,
  title = {Pawn {{Structure}} - {{Chessprogramming}} Wiki},
  url = {https://www.chessprogramming.org/Pawn_Structure},
  urldate = {2024-12-11},
  file = {C:\Users\ibyad\Zotero\storage\5M3H5BR7\Pawn_Structure.html}
}

@inproceedings{PDFSpamFiltering,
  title = {({{PDF}}) {{Spam Filtering}} with {{Naive Bayes}} - {{Which Naive Bayes}}?},
  booktitle = {{{ResearchGate}}},
  url = {https://www.researchgate.net/publication/221650814_Spam_Filtering_with_Naive_Bayes_-_Which_Naive_Bayes},
  urldate = {2025-03-20},
  abstract = {PDF | Naive Bayes is very popular in commercial and open-source anti-spam e-mail filters. There are, however, several forms of Naive Bayes, something... | Find, read and cite all the research you need on ResearchGate},
  langid = {english}
}

@online{plaatResearchReSearch2024,
  title = {Research {{Re}}: Search \& {{Re-search}}},
  shorttitle = {Research {{Re}}},
  author = {Plaat, Aske},
  date = {2024-03-20},
  eprint = {2403.13705},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.13705},
  url = {http://arxiv.org/abs/2403.13705},
  urldate = {2024-12-10},
  abstract = {Search algorithms are often categorized by their node expansion strategy. One option is the depth-first strategy, a simple backtracking strategy that traverses the search space in the order in which successor nodes are generated. An alternative is the best-first strategy, which was designed to make it possible to use domain-specific heuristic information. By exploring promising parts of the search space first, best-first algorithms are usually more efficient than depth-first algorithms. In programs that play minimax games such as chess and checkers, the efficiency of the search is of crucial importance. Given the success of best-first algorithms in other domains, one would expect them to be used for minimax games too. However, all high-performance game-playing programs are based on a depth-first algorithm. This study takes a closer look at a depth-first algorithm, AB, and a best-first algorithm, SSS. The prevailing opinion on these algorithms is that SSS offers the potential for a more efficient search, but that its complicated formulation and exponential memory requirements render it impractical. The theoretical part of this work shows that there is a surprisingly straightforward link between the two algorithms -- for all practical purposes, SSS is a special case of AB. Subsequent empirical evidence proves the prevailing opinion on SSS to be wrong: it is not a complicated algorithm, it does not need too much memory, and it is also not more efficient than depth-first search.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\LG7F9Y4R\\Plaat - 2024 - Research Re search & Re-search.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\QBNIG2GN\\2403.html}
}

@article{rishEmpiricalStudyNaive,
  title = {An Empirical Study of the Naive {{Bayes}} Classifier},
  author = {Rish, I},
  abstract = {The naive Bayes classifier greatly simplify learning by assuming that features are independent given class. Although independence is generally a poor assumption, in practice naive Bayes often competes well with more sophisticated classifiers.},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\QF975NXA\Rish - An empirical study of the naive Bayes classiﬁer.pdf}
}

@book{russellArtificialIntelligenceModern2022,
  title = {Artificial Intelligence: A Modern Approach},
  shorttitle = {Artificial Intelligence},
  author = {Russell, Stuart J. and Norvig, Peter},
  namea = {Chang, Ming-wei and Devlin, Jacob and Dragan, Anca and Forsyth, David and Goodfellow, Ian and Malik, Jitendra and Mansinghka, Vikash and Pearl, Judea and Wooldridge, Michael J.},
  nameatype = {collaborator},
  date = {2022},
  series = {Prentice {{Hall}} Series in Artificial Intelligence},
  edition = {Fourth edition, global edition},
  publisher = {Pearson},
  location = {Boston},
  abstract = {The most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence The long-anticipated revision of Artificial Intelligence: A Modern Approach explores the full breadth and depth of the field of artificial intelligence (AI). The 4th Edition brings readers up to date on the latest technologies, present concepts in a more unified manner, and offers new or expanded coverage of machine learning, deep learning, transfer learning, multi agent systems, robotics, natural language processing, causality, probabilistic programming, privacy, fairness, and safe AI},
  isbn = {978-1-292-40113-3 978-1-292-40117-1},
  langid = {english},
  pagetotal = {1},
  file = {C:\Users\ibyad\Zotero\storage\7U6VB6DJ\Russell and Norvig - 2022 - Artificial intelligence a modern approach.pdf}
}

@article{sahamiBayesianApproachFiltering,
  title = {A {{Bayesian Approach}} to {{Filtering Junk E-Mail}}},
  author = {Sahami, Mehran and Dumais, Susan and Heckerman, David and Horvitz, Eric},
  abstract = {In addressing the growingproblemof junk E-mail on the Internet, we examine methodsfor the automated construction of filters to eliminate such unwantedmessages froma user’s mail stream. Bycasting this problem in a decision theoretic framework,weare able to makeuse of probabilistic learning methodsin conjunction with a notion of differential misclassification cost to producefilters Whichare especially appropriate for the nuances of this task. Whilethis mayappear, at first, to be a straight-forwardtext classification problem, weshowthat by considering domain-specific features of this problemin addition to the raw text of E-mail messages, we can produce muchmore accurate filters. Finally, weshowthe efficacyof suchfilters in a real worldusage scenario, arguingthat this technology is mature enoughfor deployment.},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\645I94PM\Sahami et al. - A Bayesian Approach to Filtering Junk E-Mail.pdf}
}

@article{schachBachelorThesisOlegArenz,
  title = {Bachelor-Thesis von Oleg Arenz aus Wiesbaden April 2012},
  author = {Schach, Monte Carlo},
  langid = {ngerman},
  file = {C:\Users\ibyad\Zotero\storage\QKV59KR4\Schach - Bachelor-Thesis von Oleg Arenz aus Wiesbaden April 2012.pdf}
}

@article{shannonXXIIProgrammingComputer1950,
  title = {{{XXII}}. {{Programming}} a Computer for Playing Chess},
  author = {Shannon, Claude E.},
  date = {1950-03},
  journaltitle = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  shortjournal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume = {41},
  number = {314},
  pages = {256--275},
  issn = {1941-5982, 1941-5990},
  doi = {10.1080/14786445008521796},
  url = {http://www.tandfonline.com/doi/abs/10.1080/14786445008521796},
  urldate = {2024-12-12},
  langid = {english},
  file = {C:\Users\ibyad\Zotero\storage\KHGF4MNK\Shannon - 1950 - XXII. Programming a computer for playing chess.pdf}
}

@article{silverGeneralReinforcementLearning2018,
  title = {A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and {{Go}} through Self-Play},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
  date = {2018-12-07},
  journaltitle = {Science},
  volume = {362},
  number = {6419},
  pages = {1140--1144},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aar6404},
  url = {https://www.science.org/doi/10.1126/science.aar6404},
  urldate = {2024-12-12},
  abstract = {The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
  file = {C:\Users\ibyad\Zotero\storage\SIP4Z8EY\Silver et al. - 2018 - A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.pdf}
}

@article{stephensMechanicalTurkShort2023,
  title = {The Mechanical {{Turk}}: A Short History of ‘Artificial Artificial Intelligence’},
  shorttitle = {The Mechanical {{Turk}}},
  author = {Stephens, Elizabeth},
  date = {2023-01-02},
  journaltitle = {Cultural Studies},
  volume = {37},
  number = {1},
  pages = {65--87},
  publisher = {Routledge},
  issn = {0950-2386},
  doi = {10.1080/09502386.2022.2042580},
  url = {https://www.tandfonline.com/doi/full/10.1080/09502386.2022.2042580},
  urldate = {2025-03-21},
  keywords = {artificial artificial intelligence,automata,cognitive labour,Human Intelligence Tasks,Mechanical Turk,microwork platforms},
  file = {C:\Users\ibyad\Zotero\storage\AUC36C9U\Stephens - 2023 - The mechanical Turk a short history of ‘artificial artificial intelligence’.pdf}
}

@inproceedings{ulhassanComparisonMachineLearning2018,
  title = {Comparison of {{Machine Learning Algorithms}} in {{Data}} Classification},
  booktitle = {2018 24th {{International Conference}} on {{Automation}} and {{Computing}} ({{ICAC}})},
  author = {Ul Hassan, Ch Anwar and Khan, Muhammad Sufyan and Shah, Munam Ali},
  date = {2018-09},
  pages = {1--6},
  doi = {10.23919/IConAC.2018.8748995},
  url = {https://ieeexplore.ieee.org/document/8748995/?arnumber=8748995},
  urldate = {2025-03-13},
  abstract = {Data Mining is used to extract the valuable information from raw data. The task of data mining is to utilize the historical data to discover hidden patterns that helpful for future decisions. To analyze the data machine learning classifiers are used. Various data mining approaches and machine learning classifiers are applied for prediction of diseases. Where can supports, in timely treatment. The aim of this work is to compare the performance of ML classifier. These ML classifiers are Logistic Regression, Decision Tree, Niven Bayes, k-Nearest Neighbors, Support Vector Machine and Random Forests classifiers on two datasets on the basis of its accuracy, precision and f measure. The experimental results reveal that it's found that the Random Forests performance is better than the other classifiers. It gives 83\% accuracy in heart data sets and 85\% accuracy in hepatitis disease prediction.},
  eventtitle = {2018 24th {{International Conference}} on {{Automation}} and {{Computing}} ({{ICAC}})},
  keywords = {Classification algorithms,Data Analysis,Data mining,Data Mining,Diseases,Heart,Kidney,Machine learning,Machine Learning,Support vector machines},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\WM4TFRDI\\Ul Hassan et al. - 2018 - Comparison of Machine Learning Algorithms in Data classification.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\DWQ2F8WA\\8748995.html}
}

@online{WhatAreNaive2021,
  title = {What {{Are Naïve Bayes Classifiers}}? | {{IBM}}},
  shorttitle = {What {{Are Naïve Bayes Classifiers}}?},
  date = {2021-10-06T00:00:00.000},
  url = {https://www.ibm.com/topics/naive-bayes},
  urldate = {2024-12-11},
  abstract = {The Naïve Bayes classifier is a supervised machine learning algorithm that is used for classification tasks such as text classification.},
  langid = {english}
}

@incollection{xieResearchImprovementAlphaBeta2022,
  title = {Research and {{Improvement}} of {{Alpha-Beta Search Algorithm}} in {{Gobang}}},
  author = {Xie, Yuan and Gao, Wenliang and Dai, Zuxu and Li, Yuanyuan},
  date = {2022-02-01},
  doi = {10.3233/ATDE220084},
  url = {https://www.researchgate.net/publication/367787222_Research_and_Improvement_of_Alpha-Beta_Search_Algorithm_in_Gobang},
  urldate = {2024-12-10},
  abstract = {PDF | In allusion to the Alpha-Beta search algorithm which is widely used in Gobang intelligent algorithm, this paper presents an improved method, that... | Find, read and cite all the research you need on ResearchGate},
  isbn = {978-1-64368-254-9},
  langid = {english},
  file = {C\:\\Users\\ibyad\\Zotero\\storage\\2RAQS9UW\\2024 - (PDF) Research and Improvement of Alpha-Beta Search Algorithm in Gobang.pdf;C\:\\Users\\ibyad\\Zotero\\storage\\FEKH6S4Z\\367787222_Research_and_Improvement_of_Alpha-Beta_Search_Algorithm_in_Gobang.html}
}
